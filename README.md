# Kortex - Bidirectional Sign Language Translation System

Complete sign language translation system with **signâ†’text** and **textâ†’sign** capabilities, optimized for mobile deployment.

## ğŸ“ Project Structure

```
kortex_5th_sem/
â”œâ”€â”€ sign_to_text/              # Sign â†’ Text Recognition (Main Pipeline)
â”‚   â”œâ”€â”€ model_mobile.py        # CNN-BiGRU model architecture
â”‚   â”œâ”€â”€ vocabulary_builder.py  # Vocabulary management (5K words)
â”‚   â”œâ”€â”€ train.py              # Training script (optimized for RTX 4070)
â”‚   â”œâ”€â”€ export.py             # Export to ONNX/TFLite
â”‚   â”œâ”€â”€ test_realtime.py      # Webcam real-time testing
â”‚   â””â”€â”€ checkpoints/          # Saved models (created during training)
â”‚
â”œâ”€â”€ text_to_sign/              # Text â†’ Sign Generation (Experimental)
â”‚   â”œâ”€â”€ model_text_to_sign.py # Transformer encoder-decoder
â”‚   â”œâ”€â”€ train_text_to_sign.py # Training script (optimized for RTX 4060)
â”‚   â”œâ”€â”€ export_text_to_sign.py# Export to mobile formats
â”‚   â”œâ”€â”€ test_generation.py    # Generate & visualize signs
â”‚   â”œâ”€â”€ EXPERIMENT_PLAN.md    # Complete experimental guide
â”‚   â””â”€â”€ checkpoints/          # Saved models (created during training)
â”‚
â”œâ”€â”€ data/                      # Dataset & Processing
â”‚   â”œâ”€â”€ iSign_v1.1.csv        # Dataset metadata (127K samples)
â”‚   â”œâ”€â”€ extract_landmarks.py  # Multi-core landmark extraction
â”‚   â””â”€â”€ number_of_frames_test.py
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â””â”€â”€ README_SIGN_TO_TEXT.md # Detailed signâ†’text guide
â”‚
â”œâ”€â”€ SURYA/                     # Original experimental scripts
â”‚   â””â”€â”€ (legacy code)
â”‚
â””â”€â”€ kortex/                    # Python virtual environment
```

---

## ğŸš€ Quick Start

### Prerequisites
```bash
# Ensure CUDA is available
nvcc --version

# Activate environment (if using venv)
cd kortex_5th_sem
.\kortex\Scripts\Activate.ps1

# Install dependencies
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas opencv-python mediapipe tqdm matplotlib
```

---

## ğŸ“Š Dataset Setup

**Dataset**: iSign v1.1 (Indian Sign Language)
- **Location**: `data/iSign_v1.1.csv`
- **Size**: 127,237 full-sentence samples
- **Landmarks**: Must be extracted first (see below)

### Extract Landmarks (One-time)
```bash
cd data
python extract_landmarks.py
```
**Output**: `.npy` files in `E:/5thsem el/output/` (138 features per frame)

---

## ğŸ¯ Training Both Models (Dual-GPU Setup)

### Machine 1: RTX 4070 (12GB) - Sign â†’ Text
```bash
cd sign_to_text

# 1. Build vocabulary (first time only)
python vocabulary_builder.py

# 2. Train model (2-3 hours with batch_size=64)
python train.py

# 3. Export to mobile
python export.py

# 4. Test with webcam
python test_realtime.py
```

**Model**: CNN-BiGRU, ~1.4-1.6 MB quantized, <100ms inference

---

### Machine 2: RTX 4060 (8GB) - Text â†’ Sign
```bash
cd text_to_sign

# 1. Train model (3-4 hours with batch_size=20, mixed precision)
python train_text_to_sign.py

# 2. Export to mobile
python export_text_to_sign.py

# 3. Test generation
python test_generation.py
```

**Model**: Transformer, ~8-10 MB quantized, ~100ms inference

---

## âš™ï¸ Configuration

### Sign â†’ Text (`sign_to_text/train.py`)
```python
class Config:
    csv_path = "../data/iSign_v1.1.csv"
    landmarks_dir = "E:/5thsem el/output"  # Update to your path
    vocab_path = "vocabulary.pkl"
    output_dir = "checkpoints"
    
    hidden_dim = 128
    batch_size = 64  # For RTX 4070 (use 32 for 4060)
    num_epochs = 40
    learning_rate = 1e-3
```

### Text â†’ Sign (`text_to_sign/train_text_to_sign.py`)
```python
class Config:
    CSV_PATH = "../data/iSign_v1.1.csv"
    LANDMARKS_DIR = "E:/5thsem el/output"
    VOCAB_PATH = "../sign_to_text/vocabulary.pkl"
    MODEL_SAVE_DIR = "checkpoints"
    
    HIDDEN_DIM = 256
    BATCH_SIZE = 20  # Optimized for RTX 4060
    NUM_EPOCHS = 50
    USE_AMP = True  # Mixed precision (30% faster)
```

---

## ğŸ”¥ Optimizations Applied

### Sign â†’ Text (4070)
- âœ… BiGRU instead of BiLSTM (25% fewer params, 20% faster)
- âœ… Batch size: 64 (utilize 12GB VRAM)
- âœ… num_workers: 4, pin_memory: True

### Text â†’ Sign (4060)
- âœ… Mixed precision training (30% speedup)
- âœ… Batch size: 20 (optimal for 8GB VRAM)
- âœ… Temporal smoothing loss (natural animations)
- âœ… num_workers: 2, pin_memory: True

---

## ğŸ“ˆ Expected Training Times

| Model         | GPU        | Time      | Final Size |
|---------------|------------|-----------|------------|
| Signâ†’Text     | RTX 4070   | 2-3 hours | 1.6 MB     |
| Textâ†’Sign     | RTX 4060   | 3-4 hours | 8-10 MB    |

**Total**: ~6 hours for both models trained simultaneously!

---

## ğŸ® Testing

### Sign â†’ Text (Webcam)
```bash
cd sign_to_text
python test_realtime.py
```
- Opens webcam
- Real-time hand tracking with MediaPipe
- Streaming text predictions (GPT-style)
- Press 'q' to quit

### Text â†’ Sign (Generate Animations)
```bash
cd text_to_sign
python test_generation.py
```
- Interactive text input
- Generates 2D skeleton sequences
- Saves as .npy files
- Displays first frame visualization

---

## ğŸ“± Mobile Deployment

### Flutter Integration

1. **Copy TFLite models**:
   ```
   sign_to_text/checkpoints/sign_to_text_quantized.tflite
   text_to_sign/checkpoints/text_to_sign.tflite
   ```

2. **Add to Flutter** (`pubspec.yaml`):
   ```yaml
   dependencies:
     tflite_flutter: ^0.10.0
   
   flutter:
     assets:
       - assets/models/sign_to_text_quantized.tflite
       - assets/models/text_to_sign.tflite
   ```

3. **Load & Run**:
   ```dart
   import 'package:tflite_flutter/tflite_flutter.dart';
   
   final interpreter = await Interpreter.fromAsset(
     'assets/models/sign_to_text_quantized.tflite'
   );
   ```

See `docs/README_SIGN_TO_TEXT.md` and `text_to_sign/EXPERIMENT_PLAN.md` for complete Flutter code samples.

---

## ğŸ› Troubleshooting

### CUDA Out of Memory
- **4070**: Reduce batch_size to 32
- **4060**: Reduce batch_size to 16 or HIDDEN_DIM to 192

### Vocabulary Not Found
```bash
cd sign_to_text
python vocabulary_builder.py
```

### Landmarks Not Found
```bash
cd data
python extract_landmarks.py
```

### Import Errors
All imports are now relative within each folder - no need for `NEW_TRAIN` or `experiment` paths.

---

## ğŸ“š Documentation

- **Sign â†’ Text**: `docs/README_SIGN_TO_TEXT.md`
- **Text â†’ Sign**: `text_to_sign/EXPERIMENT_PLAN.md`
- **Dataset**: iSign v1.1 (127K Indian Sign Language samples)

---

## ğŸ“ Credits

- **Dataset**: iSign v1.1 (Indian Sign Language)
- **MediaPipe**: Hand & body landmark extraction
- **PyTorch**: Model training & inference
- **Flutter**: Mobile deployment (TFLite)

---

## ğŸš¦ Status

| Component       | Status | Notes                          |
|-----------------|--------|--------------------------------|
| Landmark Extraction | âœ… | Multi-core, 127K videos processed |
| Signâ†’Text Model | âœ… | CNN-BiGRU, ready to train      |
| Textâ†’Sign Model | âœ… | Transformer, ready to train    |
| Vocabulary      | âœ… | 5K words, character fallback   |
| Export Pipeline | âœ… | ONNX, TFLite, quantization     |
| Documentation   | âœ… | Complete guides                |

**Ready for dual-GPU training! ğŸš€**

---

**Start training both models now - they'll be done in ~6 hours!**
