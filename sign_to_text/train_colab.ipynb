{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c5cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdce995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc683a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repo (or upload files)\n",
    "# Option 1: Clone from GitHub\n",
    "!git clone https://github.com/Surya-Narayan-M/kortex_5th_sem.git\n",
    "%cd kortex_5th_sem/sign_to_text\n",
    "\n",
    "# Option 2: If files are in Drive, copy them\n",
    "# !cp -r /content/drive/MyDrive/kortex_5th_sem ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install tqdm pandas numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81728fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths and preprocess data in Colab\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, '/content/kortex_5th_sem/sign_to_text')\n",
    "\n",
    "# ========== PATHS ==========\n",
    "DRIVE_RAW_DATA = \"/content/drive/MyDrive/kortex_data/output\"  # Raw landmarks (2.6 GB)\n",
    "OUTPUT_PREPROCESSED = \"/content/output_preprocessed\"  # Where preprocessed data goes\n",
    "CSV_PATH = \"/content/drive/MyDrive/kortex_data/iSign_v1.1.csv\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PREPROCESSED, exist_ok=True)\n",
    "\n",
    "# Check if raw data exists\n",
    "if not os.path.exists(DRIVE_RAW_DATA):\n",
    "    print(f\"âš ï¸ Raw data not found at {DRIVE_RAW_DATA}\")\n",
    "    print(\"Upload to: MyDrive/kortex_data/output/\")\n",
    "    print(\"(the 2.6 GB folder with .npy files from E:\\\\5thsem el\\\\output\\\\)\")\n",
    "else:\n",
    "    print(f\"âœ… Found raw data at {DRIVE_RAW_DATA}\")\n",
    "    print(f\"Files: {len(os.listdir(DRIVE_RAW_DATA))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39aad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified training config for Colab\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.amp import autocast\n",
    "from tqdm.notebook import tqdm  # Notebook version of tqdm\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(message)s', datefmt='%H:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ColabConfig:\n",
    "    \"\"\"Training configuration for Colab GPU (T4/V100)\"\"\"\n",
    "    \n",
    "    # Data paths - COLAB PATHS (using preprocessed data from earlier cell)\n",
    "    data_dir = Path(\"/content/output_preprocessed\")\n",
    "    csv_path = Path(\"/content/iSign_v1.1.csv\")\n",
    "    vocab_path = Path(\"/content/kortex_5th_sem/sign_to_text/vocabulary.pkl\")\n",
    "    checkpoint_dir = Path(\"/content/drive/MyDrive/kortex_checkpoints\")  # Save to Drive!\n",
    "    \n",
    "    # Model architecture (same as local)\n",
    "    input_dim = 414\n",
    "    hidden_dim = 384\n",
    "    embedding_dim = 256\n",
    "    encoder_layers = 3\n",
    "    decoder_layers = 2\n",
    "    num_heads = 4\n",
    "    dropout = 0.3\n",
    "    \n",
    "    # Training - Colab optimized (T4 has 16GB, V100 has 16-32GB)\n",
    "    batch_size = 16  # Larger batch on Colab!\n",
    "    gradient_accumulation = 2  # Effective batch = 32\n",
    "    epochs = 100\n",
    "    learning_rate = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-5\n",
    "    warmup_epochs = 5\n",
    "    \n",
    "    # CTC/Attention balance\n",
    "    ctc_weight_start = 0.5\n",
    "    ctc_weight_end = 0.2\n",
    "    ctc_weight_decay_epochs = 30\n",
    "    \n",
    "    # Label smoothing\n",
    "    label_smoothing = 0.1\n",
    "    \n",
    "    # Teacher forcing schedule\n",
    "    tf_start = 1.0\n",
    "    tf_end = 0.3\n",
    "    tf_decay_epochs = 40\n",
    "    \n",
    "    # Early stopping\n",
    "    patience = 15\n",
    "    min_delta = 0.001\n",
    "    \n",
    "    # Device\n",
    "    device = \"cuda\"\n",
    "    use_amp = True\n",
    "    \n",
    "    # Data loading - Colab can use more workers\n",
    "    num_workers = 2  # Colab has limited CPU\n",
    "    pin_memory = True\n",
    "    prefetch_factor = 2\n",
    "    persistent_workers = True\n",
    "    \n",
    "    # Sequence length limits\n",
    "    max_src_len = 500\n",
    "    max_tgt_len = 100\n",
    "    \n",
    "    # Validation split\n",
    "    val_ratio = 0.1\n",
    "    seed = 42\n",
    "\n",
    "print(\"Colab config loaded!\")\n",
    "print(f\"Data dir: {ColabConfig.data_dir}\")\n",
    "print(f\"Batch size: {ColabConfig.batch_size} x {ColabConfig.gradient_accumulation} = {ColabConfig.batch_size * ColabConfig.gradient_accumulation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae848f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PREPROCESSING FUNCTIONS (from preprocess.py) ==========\n",
    "\n",
    "class PreprocessConfig:\n",
    "    smoothing_sigma = 1.0\n",
    "    min_hand_span = 0.01\n",
    "    add_velocity = True\n",
    "    add_acceleration = True\n",
    "\n",
    "def normalize_landmarks(landmarks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize landmarks to be person and camera invariant\"\"\"\n",
    "    T = landmarks.shape[0]\n",
    "    \n",
    "    # Reshape: hands (126) + shoulders (6) + elbows (6)\n",
    "    hands = landmarks[:, :126].reshape(T, 2, 21, 3).copy()\n",
    "    shoulders = landmarks[:, 126:132].reshape(T, 2, 3).copy()\n",
    "    elbows = landmarks[:, 132:138].reshape(T, 2, 3).copy()\n",
    "    \n",
    "    # 1. Normalize each hand to wrist origin\n",
    "    for h in range(2):\n",
    "        wrist = hands[:, h, 0:1, :].copy()\n",
    "        hands[:, h] = hands[:, h] - wrist\n",
    "    \n",
    "    # 2. Scale by hand span (wrist to middle fingertip)\n",
    "    for h in range(2):\n",
    "        span = np.linalg.norm(hands[:, h, 12] - hands[:, h, 0], axis=1, keepdims=True)\n",
    "        span = np.maximum(span, PreprocessConfig.min_hand_span)\n",
    "        hands[:, h] = hands[:, h] / span[:, :, np.newaxis]\n",
    "    \n",
    "    # 3. Normalize shoulders/elbows relative to body center\n",
    "    body_center = shoulders.mean(axis=1, keepdims=True)\n",
    "    shoulders = shoulders - body_center\n",
    "    elbows = elbows - body_center\n",
    "    \n",
    "    # 4. Scale body landmarks by shoulder width\n",
    "    shoulder_width = np.linalg.norm(shoulders[:, 0] - shoulders[:, 1], axis=1, keepdims=True)\n",
    "    shoulder_width = np.maximum(shoulder_width, PreprocessConfig.min_hand_span)\n",
    "    shoulders = shoulders / shoulder_width[:, :, np.newaxis]\n",
    "    elbows = elbows / shoulder_width[:, :, np.newaxis]\n",
    "    \n",
    "    # 5. Flatten back\n",
    "    normalized = np.concatenate([hands.reshape(T, -1), shoulders.reshape(T, -1), elbows.reshape(T, -1)], axis=1)\n",
    "    return normalized\n",
    "\n",
    "def compute_velocity(features: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute velocity (first-order derivative)\"\"\"\n",
    "    velocity = np.zeros_like(features)\n",
    "    velocity[1:] = features[1:] - features[:-1]\n",
    "    return velocity\n",
    "\n",
    "def compute_acceleration(velocity: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute acceleration (second-order derivative)\"\"\"\n",
    "    acceleration = np.zeros_like(velocity)\n",
    "    acceleration[1:] = velocity[1:] - velocity[:-1]\n",
    "    return acceleration\n",
    "\n",
    "def smooth_features(features: np.ndarray, sigma: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Apply Gaussian smoothing to reduce MediaPipe jitter\"\"\"\n",
    "    if sigma <= 0 or features.shape[0] < 3:\n",
    "        return features\n",
    "    return gaussian_filter1d(features, sigma=sigma, axis=0, mode='nearest')\n",
    "\n",
    "def preprocess_single_file(landmarks: np.ndarray, \n",
    "                           add_velocity: bool = True,\n",
    "                           add_acceleration: bool = True,\n",
    "                           smooth: bool = True) -> np.ndarray:\n",
    "    \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "    if landmarks.shape[0] == 0:\n",
    "        return landmarks\n",
    "    \n",
    "    if landmarks.shape[0] < 3:\n",
    "        pad_length = 3 - landmarks.shape[0]\n",
    "        landmarks = np.pad(landmarks, ((0, pad_length), (0, 0)), mode='edge')\n",
    "    \n",
    "    # 1. Normalize\n",
    "    normalized = normalize_landmarks(landmarks)\n",
    "    \n",
    "    # 2. Smooth\n",
    "    if smooth:\n",
    "        normalized = smooth_features(normalized, sigma=PreprocessConfig.smoothing_sigma)\n",
    "    \n",
    "    # 3. Velocity\n",
    "    if add_velocity:\n",
    "        velocity = compute_velocity(normalized)\n",
    "        if smooth:\n",
    "            velocity = smooth_features(velocity, sigma=PreprocessConfig.smoothing_sigma)\n",
    "    \n",
    "    # 4. Acceleration\n",
    "    if add_acceleration and add_velocity:\n",
    "        acceleration = compute_acceleration(velocity)\n",
    "        if smooth:\n",
    "            acceleration = smooth_features(acceleration, sigma=PreprocessConfig.smoothing_sigma)\n",
    "    \n",
    "    # 5. Concatenate\n",
    "    features = [normalized]\n",
    "    if add_velocity:\n",
    "        features.append(velocity)\n",
    "    if add_acceleration and add_velocity:\n",
    "        features.append(acceleration)\n",
    "    \n",
    "    return np.concatenate(features, axis=1)\n",
    "\n",
    "print(\"âœ… Preprocessing functions loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN PREPROCESSING ==========\n",
    "import shutil\n",
    "\n",
    "# Check if preprocessing already done\n",
    "existing_files = len(os.listdir(OUTPUT_PREPROCESSED))\n",
    "raw_files = len(os.listdir(DRIVE_RAW_DATA))\n",
    "\n",
    "if existing_files == raw_files:\n",
    "    print(f\"âœ… Preprocessing already complete! {existing_files} files found.\")\n",
    "else:\n",
    "    print(f\"ðŸ”„ Starting preprocessing: {raw_files} files\")\n",
    "    print(f\"(This will take ~10-20 minutes depending on Colab speed)\")\n",
    "    \n",
    "    # Preprocess all files\n",
    "    for filename in tqdm(sorted(os.listdir(DRIVE_RAW_DATA))):\n",
    "        if not filename.endswith('.npy'):\n",
    "            continue\n",
    "        \n",
    "        input_path = os.path.join(DRIVE_RAW_DATA, filename)\n",
    "        output_path = os.path.join(OUTPUT_PREPROCESSED, filename)\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if os.path.exists(output_path):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load raw landmarks\n",
    "            landmarks = np.load(input_path)  # (T, 138)\n",
    "            \n",
    "            # Preprocess\n",
    "            preprocessed = preprocess_single_file(landmarks)  # (T, 414)\n",
    "            \n",
    "            # Save\n",
    "            np.save(output_path, preprocessed)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Preprocessing complete! {len(os.listdir(OUTPUT_PREPROCESSED))} files saved\")\n",
    "\n",
    "# Copy CSV to Colab if not there\n",
    "if not os.path.exists('/content/iSign_v1.1.csv'):\n",
    "    shutil.copy(CSV_PATH, '/content/iSign_v1.1.csv')\n",
    "    print(\"âœ… CSV copied to /content/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bea998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model and training components from your repo\n",
    "from model_hybrid import HybridCTCAttentionModel\n",
    "\n",
    "# Test model creation\n",
    "model = HybridCTCAttentionModel(\n",
    "    input_dim=414,\n",
    "    hidden_dim=384,\n",
    "    vocab_size=73\n",
    ").cuda()\n",
    "\n",
    "print(f\"Model parameters: {model.get_num_params():,}\")\n",
    "print(f\"Model size: {model.get_model_size_mb():.2f} MB\")\n",
    "\n",
    "# Quick forward test\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(4, 100, 414).cuda()\n",
    "    lens = torch.tensor([100, 90, 80, 70]).cuda()\n",
    "    tgt = torch.randint(0, 73, (4, 20)).cuda()\n",
    "    ctc_out, attn_out = model(x, lens, tgt)\n",
    "    print(f\"CTC output: {ctc_out.shape}\")\n",
    "    print(f\"Attn output: {attn_out.shape}\")\n",
    "print(\"âœ… Model works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training components\n",
    "from train_hybrid import (\n",
    "    SignLanguageDataset, \n",
    "    collate_fn, \n",
    "    HybridLoss,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Patch the Trainer to use Colab config\n",
    "class ColabTrainer(Trainer):\n",
    "    def __init__(self):\n",
    "        # Use Colab config instead\n",
    "        super().__init__(ColabConfig())\n",
    "\n",
    "print(\"Training components imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer and start training!\n",
    "trainer = ColabTrainer()\n",
    "\n",
    "print(f\"Train samples: {len(trainer.train_dataset)}\")\n",
    "print(f\"Val samples: {len(trainer.val_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(trainer.train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d402ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "# To resume from checkpoint: trainer.train(resume_from=\"/content/drive/MyDrive/kortex_checkpoints/latest.pth\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e347b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training (run after training or during breaks)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = trainer.history\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0,0].plot(history['train_loss'], label='Train')\n",
    "axes[0,0].plot(history['val_loss'], label='Val')\n",
    "axes[0,0].set_title('Total Loss')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[0,1].plot([a*100 for a in history['train_acc']], label='Train')\n",
    "axes[0,1].plot([a*100 for a in history['val_acc']], label='Val')\n",
    "axes[0,1].set_title('Accuracy (%)')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# CTC Loss\n",
    "axes[1,0].plot(history['train_ctc_loss'], label='Train CTC')\n",
    "axes[1,0].plot(history['val_ctc_loss'], label='Val CTC')\n",
    "axes[1,0].set_title('CTC Loss')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Attention Loss\n",
    "axes[1,1].plot(history['train_attn_loss'], label='Train Attn')\n",
    "axes[1,1].plot(history['val_attn_loss'], label='Val Attn')\n",
    "axes[1,1].set_title('Attention Loss')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/kortex_checkpoints/training_curves.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Val Loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"Best Val Acc: {max(history['val_acc'])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model to Drive\n",
    "!cp /content/kortex_5th_sem/sign_to_text/checkpoints_hybrid/* /content/drive/MyDrive/kortex_checkpoints/\n",
    "print(\"Checkpoints saved to Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kortex (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
